{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocess_modules import utilities_hrv as hrvutils\n",
    "from preprocess_modules import utilities_e4 as e4utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File paths and regex for reading in participant E4 data folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "e4_dir = r\"P:\\Spironolactone\\E4\"\n",
    "main_dir = r\"P:\\Spironolactone\\main_qualtrics\"\n",
    "participant_folders = os.listdir(e4_dir)\n",
    "# use a regex pattern to search for folders starting with p and two integers in the range 0-9\n",
    "# note that it doesn't matter whether p is lower or upper case in the folder name due to including f.lower()\n",
    "participant_folders = [f for f in participant_folders if re.search(\"^p[0][0-9][0-9]\",f.lower())] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-904f81354a9d>:6: UserWarning: Directory already exists. Files may be overwritten. Manual check advised.\n",
      "  warnings.warn(\"Directory already exists. Files may be overwritten. Manual check advised.\")\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(e4_dir,\"processed_e4_files\")\n",
    "try:\n",
    "    os.makedirs(output_dir)\n",
    "except OSError:\n",
    "    # if directory already exists\n",
    "    warnings.warn(\"Directory already exists. Files may be overwritten. Manual check advised.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is basically the same as in the HRV preprocessing file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following participants have duplicate records:\n",
      "[4.]\n"
     ]
    }
   ],
   "source": [
    "col_list =  [\"Status\",\"DQ-1\",\"Firstbeat_on_time\",\"baseline start\",\"baseline end\",\"Q645\",\"Q646\",\"FILM-START\",\"Q648\",\"Q649\"]\n",
    "new_names = [\"Response_type\",\"Participant_number\",\"Firstbeat_start\",\"RT1_start\",\"RT1_end\",\"RT2_start\",\"RT2_end\",\"Film_start\",\"RT3_start\",\"RT3_end\"]\n",
    "qualtrics_df = pd.read_csv(os.path.join(main_dir,\"main_dat.csv\"),usecols =col_list,skiprows= [1,2])\n",
    "qualtrics_df.columns = new_names\n",
    "\n",
    "qualtrics_df = hrvutils.remove_invalid_records(qualtrics_df,\"Participant_number\",exclude_pnums = [1])\n",
    "duplicates = hrvutils.flag_duplicate_participants(qualtrics_df,\"Participant_number\")\n",
    "qualtrics_df = hrvutils.remove_duplicate_participants(qualtrics_df,\"Participant_number\")\n",
    "qualtrics_df = hrvutils.convert_time_cols(qualtrics_df)\n",
    "qualtrics_df = hrvutils.add_end_time(qualtrics_df,\"Film_start\",15)\n",
    "rt_time_cols = [f for f in qualtrics_df.columns if any(k in f for k in [\"start\",\"end\"])]\n",
    "for rt_time in rt_time_cols[1:]:\n",
    "    qualtrics_df = hrvutils.make_rel_time_cols(qualtrics_df,rt_time_cols[0],rt_time)\n",
    "qualtrics_df = hrvutils.convert_to_secs(qualtrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read in the skin conductance (EDA) files.\n",
    "This does the usual, ie checking that a file exists for the participant and flagging duplicates, missing files or short recordings.\n",
    "Short recordings are identified based on a pretty arbitrary threshold. Below I flag everything with a duration <4 hours, but you can adapt that as you see fit.\n",
    "As in the HRV version, this will cut the EDA file for each participant into sections for RT1, RT2, film and RT3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than one file exists for participant 1. Skipping.\n",
      "More than one file exists for participant 1. Skipping.\n",
      "More than one file exists for participant 10. Skipping.\n",
      "More than one file exists for participant 10. Skipping.\n",
      "Recording for participant 12 seems short. Manual check advised.\n",
      "Recording for participant 14 seems short. Manual check advised.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-2350220e7d99>:37: UserWarning: Participant 13 has no valid data for RT2 interval.\n",
      "Manual check advised.\n",
      "  warnings.warn(f\"Participant {pnum} has no valid data for {interval_name} interval.\\nManual check advised.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for participant 18 seems short. Manual check advised.\n",
      "More than one file exists for participant 20. Skipping.\n",
      "More than one file exists for participant 20. Skipping.\n",
      "More than one file exists for participant 27. Skipping.\n",
      "More than one file exists for participant 27. Skipping.\n"
     ]
    }
   ],
   "source": [
    "start_intervals = qualtrics_df.filter(like = \"start_interval\", axis = 1).columns.sort_values()\n",
    "end_intervals = qualtrics_df.filter(like = \"end_interval\", axis = 1).columns.sort_values()\n",
    "intervals = list(zip(start_intervals, end_intervals))\n",
    "\n",
    "missing_eda = []\n",
    "pnums = []\n",
    "eda_dat = []\n",
    "below_min = []\n",
    "missing_sec = []\n",
    "duplicates = e4utils.flag_duplicates(participant_folders)\n",
    "# somewhat arbitrary. If length of EDA recording indicates that session<4 hours, flag this.\n",
    "# the formula for calculating min_session_length is: hours*minutes_per_hour*seconds_per_minute*sampling_rate\n",
    "min_session_length = 4*60*60*4\n",
    "\n",
    "\n",
    "for folder in participant_folders:\n",
    "    pnum = e4utils.get_participant_num(folder)\n",
    "    if pnum in duplicates:\n",
    "        print(f\"More than one file exists for participant {pnum}. Skipping.\")\n",
    "        continue\n",
    "    try:\n",
    "        eda_df = pd.read_csv(os.path.join(e4_dir,folder,\"EDA.csv\"),header = None,names = [\"EDA\"])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No E4 file found for participant {pnum}.Manual check advised.\")\n",
    "        missing_eda.append(pnum)\n",
    "        continue\n",
    "    if eda_df.shape[0]<min_session_length:\n",
    "        print(f\"Recording for participant {pnum} seems short. Manual check advised.\")\n",
    "        below_min.append(pnum)\n",
    "        continue\n",
    "    for start, stop in intervals:\n",
    "        start_val = qualtrics_df.loc[qualtrics_df.Participant_number == pnum,start]\n",
    "        stop_val = qualtrics_df.loc[qualtrics_df.Participant_number == pnum,stop]\n",
    "        interval_df = e4utils.get_eda_intervals(eda_df,start_val,stop_val,4)\n",
    "        if interval_df.empty:\n",
    "            interval_name = start.split(\"_\")[0]\n",
    "            warnings.warn(f\"Participant {pnum} has no valid data for {interval_name} interval.\\nManual check advised.\")\n",
    "            missing_sec.append([pnum,interval_name])\n",
    "            continue\n",
    "        # save to file\n",
    "        interval_df.to_csv(os.path.join(output_dir, \"_\".join([start.split(\"_\")[0],str(int(pnum)),\"eda.csv\"])),index = False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48186e61764c8c514947f0ef500accf59797b98e64cdc910e21ec2975c1f1025"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
