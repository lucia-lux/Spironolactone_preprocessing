{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports.\n",
    "Note that this is almost the same as (or at least very similar to) the hrv segmentation program.\n",
    "The main difference is that the files are organized a little bit differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocess_modules import utilities_hrv as hrvutils\n",
    "from preprocess_modules import utilities_e4 as e4utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File paths and regex for reading in participant E4 data folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "e4_dir = r\"P:\\Spironolactone\\E4\"\n",
    "main_dir = r\"P:\\Spironolactone\\main_qualtrics\"\n",
    "participant_folders = os.listdir(e4_dir)\n",
    "# use a regex pattern to search for folders starting with p and two integers in the range 0-9\n",
    "# note that it doesn't matter whether p is lower or upper case in the folder name due to including f.lower()\n",
    "participant_folders = [f for f in participant_folders if re.search(\"^p[0][0-9][0-9]\",f.lower())] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-904f81354a9d>:6: UserWarning: Directory already exists. Files may be overwritten. Manual check advised.\n",
      "  warnings.warn(\"Directory already exists. Files may be overwritten. Manual check advised.\")\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(e4_dir,\"processed_e4_files\")\n",
    "try:\n",
    "    os.makedirs(output_dir)\n",
    "except OSError:\n",
    "    # if directory already exists\n",
    "    warnings.warn(\"Directory already exists. Files may be overwritten. Manual check advised.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is basically the same as in the HRV preprocessing file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following participants have duplicate records:\n",
      "[4.]\n"
     ]
    }
   ],
   "source": [
    "col_list =  [\"Status\",\"DQ-1\",\"Firstbeat_on_time\",\"baseline start\",\"baseline end\",\"Q645\",\"Q646\",\"FILM-START\",\"Q648\",\"Q649\"]\n",
    "new_names = [\"Response_type\",\"Participant_number\",\"Firstbeat_start\",\"RT1_start\",\"RT1_end\",\"RT2_start\",\"RT2_end\",\"Film_start\",\"RT3_start\",\"RT3_end\"]\n",
    "qualtrics_df = pd.read_csv(os.path.join(main_dir,\"main_dat.csv\"),usecols =col_list,skiprows= [1,2])\n",
    "qualtrics_df.columns = new_names\n",
    "\n",
    "qualtrics_df = hrvutils.remove_invalid_records(qualtrics_df,\"Participant_number\",exclude_pnums = [1])\n",
    "duplicates = hrvutils.flag_duplicate_participants(qualtrics_df,\"Participant_number\")\n",
    "qualtrics_df = hrvutils.remove_duplicate_participants(qualtrics_df,\"Participant_number\")\n",
    "qualtrics_df = hrvutils.convert_time_cols(qualtrics_df)\n",
    "qualtrics_df = hrvutils.add_end_time(qualtrics_df,\"Film_start\",15)\n",
    "rt_time_cols = [f for f in qualtrics_df.columns if any(k in f for k in [\"start\",\"end\"])]\n",
    "for rt_time in rt_time_cols[1:]:\n",
    "    qualtrics_df = hrvutils.make_rel_time_cols(qualtrics_df,rt_time_cols[0],rt_time)\n",
    "qualtrics_df = hrvutils.convert_to_secs(qualtrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read in the skin conductance (EDA) files.\n",
    "This does the usual, ie checking that a file exists for the participant and flagging duplicates, missing files or short recordings.\n",
    "Short recordings are identified based on a pretty arbitrary threshold. Below I flag everything with a duration <4 hours, but you can adapt that as you see fit.\n",
    "As in the HRV version, this will cut the EDA file for each participant into sections for RT1, RT2, film and RT3.\n",
    "At the start I'm checking whether there is an EDA file for each participant and whether this participant has a record in the qualtrics file. Sometimes there are discrepancies, depending on how up to date the respective data sources are.\n",
    "I'm also catching type/value errors for the start/end times of intervals. This is because I had issues with nan values before I realised that these were being caused by an out-of-date qualtrics file. You could take the try/except block out but it's nice to have it there, just in case there is no qualtrics time stamp for whatever reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Participant 1 not in qualtrics file. Skipping.\n",
      " Participant 1 not in qualtrics file. Skipping.\n",
      "More than one file exists for participant 10. Skipping.\n",
      "More than one file exists for participant 10. Skipping.\n",
      "Recording for participant 12 seems short. Manual check advised.\n",
      "Recording for participant 14 seems short. Manual check advised.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-0a0416270bef>:46: UserWarning: Participant 13 has no valid data for RT2 interval.\n",
      "Manual check advised.\n",
      "  warnings.warn(f\"Participant {pnum} has no valid data for {interval_name} interval.\\nManual check advised.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for participant 18 seems short. Manual check advised.\n",
      "More than one file exists for participant 20. Skipping.\n",
      "More than one file exists for participant 20. Skipping.\n",
      "More than one file exists for participant 27. Skipping.\n",
      "More than one file exists for participant 27. Skipping.\n",
      "At least one of start_val, stop_val not int. Skipping participant 39.\n",
      " Participant 42 not in qualtrics file. Skipping.\n",
      " Participant 43 not in qualtrics file. Skipping.\n",
      " Participant 44 not in qualtrics file. Skipping.\n",
      " Participant 45 not in qualtrics file. Skipping.\n",
      " Participant 45 not in qualtrics file. Skipping.\n",
      " Participant 46 not in qualtrics file. Skipping.\n",
      " Participant 47 not in qualtrics file. Skipping.\n"
     ]
    }
   ],
   "source": [
    "start_intervals = qualtrics_df.filter(like = \"start_interval\", axis = 1).columns.sort_values()\n",
    "end_intervals = qualtrics_df.filter(like = \"end_interval\", axis = 1).columns.sort_values()\n",
    "intervals = list(zip(start_intervals, end_intervals))\n",
    "qualtrics_pnums = qualtrics_df.Participant_number.values\n",
    "\n",
    "missing_eda = []\n",
    "pnums = []\n",
    "eda_dat = []\n",
    "below_min = []\n",
    "missing_sec = []\n",
    "duplicates = e4utils.flag_duplicates(participant_folders)\n",
    "# somewhat arbitrary. If length of EDA recording indicates that session<4 hours, flag this.\n",
    "# the formula for calculating min_session_length is: hours*minutes_per_hour*seconds_per_minute*sampling_rate\n",
    "min_session_length = 4*60*60*4\n",
    "\n",
    "\n",
    "for folder in participant_folders:\n",
    "    pnum = e4utils.get_participant_num(folder)\n",
    "    if pnum not in qualtrics_pnums:\n",
    "        print(f\" Participant {pnum} not in qualtrics file. Skipping.\")\n",
    "        continue\n",
    "    if pnum in duplicates:\n",
    "        print(f\"More than one file exists for participant {pnum}. Skipping.\")\n",
    "        continue\n",
    "    try:\n",
    "        eda_df = pd.read_csv(os.path.join(e4_dir,folder,\"EDA.csv\"),header = None,names = [\"EDA\"])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No E4 file found for participant {pnum}.Manual check advised.\")\n",
    "        missing_eda.append(pnum)\n",
    "        continue\n",
    "    if eda_df.shape[0]<min_session_length:\n",
    "        print(f\"Recording for participant {pnum} seems short. Manual check advised.\")\n",
    "        below_min.append(pnum)\n",
    "        continue\n",
    "    for start, stop in intervals:\n",
    "        start_val = qualtrics_df.loc[qualtrics_df.Participant_number == pnum,start]\n",
    "        stop_val = qualtrics_df.loc[qualtrics_df.Participant_number == pnum,stop]\n",
    "        try:\n",
    "            [int(val) for val in [start_val, stop_val]]\n",
    "        except (ValueError, TypeError) as e:\n",
    "            print(f\"At least one of start_val, stop_val not int. Skipping participant {pnum}.\")\n",
    "            continue\n",
    "        interval_df = e4utils.get_eda_intervals(eda_df,start_val,stop_val,4)\n",
    "        if interval_df.empty:\n",
    "            interval_name = start.split(\"_\")[0]\n",
    "            warnings.warn(f\"Participant {pnum} has no valid data for {interval_name} interval.\\nManual check advised.\")\n",
    "            missing_sec.append([pnum,interval_name])\n",
    "            continue\n",
    "        # save to file\n",
    "        interval_df.to_csv(os.path.join(output_dir, \"_\".join([start.split(\"_\")[0],str(int(pnum)),\"eda.csv\"])),index = False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48186e61764c8c514947f0ef500accf59797b98e64cdc910e21ec2975c1f1025"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
