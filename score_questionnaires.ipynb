{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking __init__.py for preprocess_modules\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess_modules import utilities_hrv as hrvutils\n",
    "from preprocess_modules import utilities as dutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_main(in_df, select_list):\n",
    "    \"\"\"\n",
    "    Select columns to process.\n",
    "    Main qualtrics version.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df:  pd DataFrame\n",
    "        dataframe to operate on\n",
    "    select_list: list[str]\n",
    "        names of columns to retain\n",
    "    Returns\n",
    "    -------\n",
    "    in_df with only specified columns\n",
    "    \"\"\"\n",
    "    in_df = in_df.loc[:,select_list]\n",
    "    return in_df\n",
    "\n",
    "def remove_newlines(in_df, rounds = 1):\n",
    "    \"\"\"\n",
    "    Remove newlines from text.\n",
    "    if rounds = 1, just remove leading\n",
    "    and trailing newlines\n",
    "    if rounds > 1, additionally replace\n",
    "    newlines in text with whitespace.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df:  pd DataFrame\n",
    "        input dataframe\n",
    "    rounds: int\n",
    "        1 or more rounds, see above\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    in_df with newlines removed\n",
    "    \"\"\"\n",
    "    if rounds == 1:\n",
    "        in_df = in_df.applymap(lambda x: x.strip())\n",
    "    else:\n",
    "        in_df = in_df.applymap(lambda x: x.strip())\n",
    "        in_df = in_df.applymap(lambda x: x.replace(\"\\n\", \" \"))\n",
    "    return in_df\n",
    "\n",
    "def make_dict(keys, values):\n",
    "    \"\"\"\n",
    "    Make dicts for questionnaire scoring\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    keys:   list[str]\n",
    "        string values of questionnaire\n",
    "        scores as they appear in qualtrics\n",
    "    values: list[int]\n",
    "        the scores corresponding to the\n",
    "        string values in keys\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        dict containing string values as keys\n",
    "        and ints for replacement as values.\n",
    "    \"\"\"\n",
    "    keys = [key.lower() for key in keys]\n",
    "    my_key_dict = dict(zip(keys,values))\n",
    "    return my_key_dict\n",
    "\n",
    "def filter_cols(in_df, substr):\n",
    "    \"\"\"\n",
    "    filter for relevant columns\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df:  pd DataFrame\n",
    "        input dataframe\n",
    "    substr: str\n",
    "        string to filter column\n",
    "        names by\n",
    "    Returns\n",
    "    -------\n",
    "        list of filtered column names\n",
    "    \"\"\"\n",
    "    return [col for col in in_df if substr in col]\n",
    "\n",
    "def repl_numeric(sub_df, key_dict):\n",
    "    \"\"\"\n",
    "    Replace strings with numeric score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sub_df: pd DataFrame\n",
    "        dataframe containing only cols\n",
    "        referring to given survey\n",
    "    key_dict:   dict\n",
    "        dictionary containing key-value pairs\n",
    "        for replacement\n",
    "    rem_newl:   \n",
    "        whether or not to remove newline characters\n",
    "        None/not provided = don't strip new lines\n",
    "        any other value = do remove them.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        sub_df, containing numeric representations of\n",
    "        questionnaire responses.\n",
    "\n",
    "    \"\"\"\n",
    "    sub_df = sub_df.applymap(lambda x: key_dict[x.lower()])\n",
    "    return sub_df\n",
    "\n",
    "def strip_unwanted(sub_df,reg_exp):\n",
    "    \"\"\"\n",
    "    Remove unwanted elements from string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sub_df: pd DataFrame\n",
    "        dataframe containing questionnaire\n",
    "        scores in string format\n",
    "    reg_exp:    str\n",
    "        this will be the first argument in\n",
    "        re.sub()\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        sub_df w/out unwanted content\n",
    "    \"\"\"\n",
    "    sub_df = sub_df.applymap(\n",
    "                            lambda x: re.sub(reg_exp,\n",
    "                            \"\",x).rstrip()\n",
    "                            )\n",
    "    return sub_df\n",
    "\n",
    "def preprocess_subdf(in_df,substr,keys,values,rem_nl = None, strip_re = None):\n",
    "    \"\"\"\n",
    "    Preprocess questionnaire scores.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df: pd DataFrame\n",
    "        main qualtrics dataframe\n",
    "    substr: str\n",
    "        substr to identify relevant columns\n",
    "    keys:   list[str]\n",
    "        scores as they appear in OG sub_df\n",
    "    values: list[int]\n",
    "        numeric scores to replace str vals with\n",
    "    remove_newlines:\n",
    "        if provided, remove any unwanted newline\n",
    "        characters\n",
    "    strip_re: str, optional\n",
    "        provide string to use in re.sub(),\n",
    "        eg for removing brackets from survey\n",
    "        scores.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        sub_df containing numeric rather than str\n",
    "        scores.\n",
    "    \"\"\"\n",
    "    sub_df = in_df.loc[:, filter_cols(in_df,substr)]\n",
    "    # remove new line characters if needed\n",
    "    if rem_nl is not None:\n",
    "        sub_df = remove_newlines(sub_df,rounds = 2)\n",
    "    if strip_re is not None:\n",
    "        sub_df = strip_unwanted(sub_df,strip_re)\n",
    "    sub_df = repl_numeric(sub_df,make_dict(keys, values))\n",
    "    return sub_df\n",
    "\n",
    "def change_header(in_df,col_names,val_range):\n",
    "    \"\"\"\n",
    "    Change head for easier multiplication.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df:  pd DataFrame\n",
    "    col_names:  list[str]\n",
    "        columns in in_df to rename\n",
    "    val_range:  array\n",
    "        range of values ot replace\n",
    "        string names with\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    subsection of input dataframe\n",
    "    with names replaced by values in\n",
    "    val_range\n",
    "    \"\"\"\n",
    "    sub_df = in_df.loc[:,col_names]\n",
    "    sub_df.columns = val_range\n",
    "    return sub_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = r\"P:\\Spironolactone\\main_qualtrics\"\n",
    "qualtrics_df = pd.read_csv(os.path.join(main_dir, \"main_dat21.csv\"), skiprows=[1,2])\n",
    "qualtrics_df = dutils.remove_incomplete_rows(qualtrics_df, \"Finished\")\n",
    "qualtrics_df = hrvutils.remove_invalid_records(qualtrics_df,\"DQ-1\",[1])\n",
    "qualtrics_df = hrvutils.remove_duplicate_participants(qualtrics_df,\"DQ-1\")\n",
    "qualtrics_df = qualtrics_df.set_index(\"DQ-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key/value pairs\n",
    "# childhood trauma questionnaire\n",
    "ctq_keys = [\"never true\",\"rarely true\", \"sometimes true\", \"often true\", \"very often true\"]\n",
    "ctq_values = np.arange(1,6)\n",
    "# STAI\n",
    "stai_keys = [\"almost never\",\"sometimes\",\"often\", \"almost always\"]\n",
    "stai_values = np.arange(1,5)\n",
    "# ERQ\n",
    "erq_keys = [\"strongly disagree\",\"disagree\",\"slightly disagree\",\"neither agree nor disagree\", \"slightly agree\", \"agree\",\"strongly agree\"]\n",
    "erq_values = np.arange(1,8)\n",
    "# PANAS\n",
    "panas_keys = [\"very slightly or not at all\", \"a little\", \"moderately\", \"quite a bit\", \"extremely\"]\n",
    "panas_values = np.arange(1,6)\n",
    "# CADSS\n",
    "cadss_keys = [\"not at all\", \"slightly\", \"moderately\", \"considerably\", \"extremely\"]\n",
    "cadss_values = np.arange(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "stai_df = preprocess_subdf(qualtrics_df,\"622_\",stai_keys,stai_values)\n",
    "ctq_df = preprocess_subdf(qualtrics_df,\"Q409_\",ctq_keys,ctq_values)\n",
    "erq_df = preprocess_subdf(qualtrics_df,\"ERQ_\",erq_keys,erq_values,2)\n",
    "panas_t1_df = preprocess_subdf(qualtrics_df,\"PANAS\",panas_keys,panas_values)\n",
    "panas_t2_df = preprocess_subdf(qualtrics_df,\"Q511_\",panas_keys,panas_values)\n",
    "panas_t3_df = preprocess_subdf(qualtrics_df,\"Q528_\",panas_keys,panas_values)\n",
    "cadss_df = preprocess_subdf(qualtrics_df, \"Q594_\",cadss_keys,cadss_values,strip_re = r\"\\([^)]*\\)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now score surveys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_affect_items_panas = [val-1 for val in [1,3,5,9,10,12,14,16,17,19]]\n",
    "neg_affect_items_panas = [val-1 for val in [2,4,6,7,8,11,13,15,18,20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PANAS\n",
    "panas_pos_scores = []\n",
    "panas_neg_scores = []\n",
    "labels = []\n",
    "for i,panas in enumerate([panas_t1_df,panas_t2_df,panas_t3_df]):\n",
    "    neg_affect = panas.iloc[:,neg_affect_items_panas].sum(axis = 1)\n",
    "    pos_affect = panas.iloc[:,pos_affect_items_panas].sum(axis = 1)\n",
    "    label = '_'.join([\"panas\",str(i)])\n",
    "    labels.append(label)\n",
    "    panas_pos_scores.append(pos_affect)\n",
    "    panas_neg_scores.append(neg_affect)\n",
    "\n",
    "sum_dict_keys = [\"panas_t1_neg\",\"panas_t1_pos\",\"panas_t2_neg\",\"panas_t2_pos\",\"panas_t3_neg\",\"panas_t3_pos\"]\n",
    "sum_dict_vals = [panas_neg_scores[0],panas_pos_scores[0], panas_neg_scores[1],panas_pos_scores[1],panas_neg_scores[2],panas_pos_scores[2]]\n",
    "panas_dict = dict(zip(sum_dict_keys, sum_dict_vals))\n",
    "panas_summary_df = pd.DataFrame(data = panas_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAI. Some items are reverse scored. You can account for this at an earlier stage (when replacing the string values).\n",
    "# Because I'd already done the preprocessing, I'll just replace the relevant vals here instead.\n",
    "stai_new_keys = stai_values\n",
    "rev_vals = list(stai_values)\n",
    "rev_vals.reverse()\n",
    "stai_dict_new = dict(zip(stai_new_keys,rev_vals))\n",
    "reverse_items = [val-21 for val in [21,23,26,27,30,33,34,36,39]]\n",
    "stai_df.iloc[:,reverse_items] = stai_df.iloc[\n",
    "                                            :,reverse_items\n",
    "                                            ].applymap(\n",
    "                                            lambda x: stai_dict_new[x]\n",
    "                                            )\n",
    "\n",
    "stai_scored = stai_df.sum(axis = 1).rename(\"stai_trait\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERQ\n",
    "cra_items = [0,3,5,6,8]\n",
    "sup_items = [1,2,4,7]\n",
    "erq_cra = erq_df.iloc[:,cra_items].sum(axis = 1).rename(\"erq_cra\")\n",
    "erq_sup = erq_df.iloc[:, sup_items].sum(axis = 1).rename(\"erq_sup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acute diary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "acute_diary_df = qualtrics_df.filter(like = \"Q195\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = []\n",
    "search_strings = [\"\".join([\"#\",str(num),\"_\"]) for num in np.arange(1,5)]\n",
    "for s in search_strings:#\n",
    "    cols = filter_cols(acute_diary_df,s)\n",
    "    use_cols.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace string vals with an integer\n",
    "# this is just an indicator as to whether or not they reported an intrusion.\n",
    "acute_diary_df = acute_diary_df.replace(\"0\",np.nan).replace(0,np.nan)\n",
    "acute_diary_df.loc[:,use_cols[0]] = acute_diary_df.loc[:,use_cols[0]].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_content_df = change_header(acute_diary_df,use_cols[0],np.arange(1,13))\n",
    "int_viv_df = change_header(acute_diary_df,use_cols[2],np.arange(1,13))\n",
    "int_dist_df = change_header(acute_diary_df,use_cols[3],np.arange(1,13))\n",
    "int_frequency_df = change_header(acute_diary_df,use_cols[1],np.arange(1,13))\n",
    "int_count = int_content_df*int_frequency_df\n",
    "viv_load = (int_frequency_df*int_viv_df).sum(axis = 1).rename(\"vividness_load\")\n",
    "dist_load = (int_frequency_df*int_dist_df).sum(axis = 1).rename(\"distress_load\")\n",
    "int_count.columns = [\"_\".join([\"memory\",str(col)]) for col in int_count.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_names = use_cols[2:]\n",
    "new_names = [\"vividness\", \"distress\"]\n",
    "\n",
    "for i,name in enumerate(old_names):\n",
    "    new_name = [\"_\".join([new_names[i],str(val)]) for val in np.arange(1,13)]\n",
    "    mydict = dict(zip(name,new_name))\n",
    "    acute_diary_df = acute_diary_df.rename(mydict,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "acute_diary_scores_df = pd.concat([int_count,acute_diary_df.iloc[:,24:]],axis = 1)\n",
    "acute_diary_scores_df[\"sum_ints\"] = acute_diary_scores_df.filter(like = \"memory\",axis = 1).sum(axis = 1)\n",
    "acute_diary_scores_df[\"vividness_load\"] = viv_load\n",
    "acute_diary_scores_df[\"distress_load\"] = dist_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores_df = pd.concat([panas_summary_df,stai_scored,erq_cra,erq_sup,acute_diary_scores_df],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores_df.to_csv(os.path.join(r\"P:\\Spironolactone\",\"study_day_scores.csv\"),index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48186e61764c8c514947f0ef500accf59797b98e64cdc910e21ec2975c1f1025"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
