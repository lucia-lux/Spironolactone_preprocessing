{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess_modules import utilities_hrv as hrvutils\n",
    "from preprocess_modules import utilities as dutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_main(in_df, select_list):\n",
    "    \"\"\"\n",
    "    Select columns to process.\n",
    "    Main qualtrics version.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df:  pd DataFrame\n",
    "        dataframe to operate on\n",
    "    select_list: list[str]\n",
    "        names of columns to retain\n",
    "    Returns\n",
    "    -------\n",
    "    in_df with only specified columns\n",
    "    \"\"\"\n",
    "    in_df = in_df.loc[:,select_list]\n",
    "    return in_df\n",
    "\n",
    "def remove_newlines(in_df, rounds = 1):\n",
    "    \"\"\"\n",
    "    Remove newlines from text.\n",
    "    if rounds = 1, just remove leading\n",
    "    and trailing newlines\n",
    "    if rounds > 1, additionally replace\n",
    "    newlines in text with whitespace.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df:  pd DataFrame\n",
    "        input dataframe\n",
    "    rounds: int\n",
    "        1 or more rounds, see above\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    in_df with newlines removed\n",
    "    \"\"\"\n",
    "    if rounds == 1:\n",
    "        in_df = in_df.applymap(lambda x: x.strip())\n",
    "    else:\n",
    "        in_df = in_df.applymap(lambda x: x.strip())\n",
    "        in_df = in_df.applymap(lambda x: x.replace(\"\\n\", \" \"))\n",
    "    return in_df\n",
    "\n",
    "def make_dict(keys, values):\n",
    "    \"\"\"\n",
    "    Make dicts for questionnaire scoring\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    keys:   list[str]\n",
    "        string values of questionnaire\n",
    "        scores as they appear in qualtrics\n",
    "    values: list[int]\n",
    "        the scores corresponding to the\n",
    "        string values in keys\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        dict containing string values as keys\n",
    "        and ints for replacement as values.\n",
    "    \"\"\"\n",
    "    keys = [key.lower() for key in keys]\n",
    "    my_key_dict = dict(zip(keys,values))\n",
    "    return my_key_dict\n",
    "\n",
    "def filter_cols(in_df, substr):\n",
    "    \"\"\"\n",
    "    filter for relevant columns\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df:  pd DataFrame\n",
    "        input dataframe\n",
    "    substr: str\n",
    "        string to filter column\n",
    "        names by\n",
    "    Returns\n",
    "    -------\n",
    "        list of filtered column names\n",
    "    \"\"\"\n",
    "    return [col for col in in_df if substr in col]\n",
    "\n",
    "def repl_numeric(sub_df, key_dict):\n",
    "    \"\"\"\n",
    "    Replace strings with numeric score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sub_df: pd DataFrame\n",
    "        dataframe containing only cols\n",
    "        referring to given survey\n",
    "    key_dict:   dict\n",
    "        dictionary containing key-value pairs\n",
    "        for replacement\n",
    "    rem_newl:   \n",
    "        whether or not to remove newline characters\n",
    "        None/not provided = don't strip new lines\n",
    "        any other value = do remove them.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        sub_df, containing numeric representations of\n",
    "        questionnaire responses.\n",
    "\n",
    "    \"\"\"\n",
    "    sub_df = sub_df.applymap(lambda x: key_dict[x.lower()])\n",
    "    return sub_df\n",
    "\n",
    "def strip_unwanted(sub_df,reg_exp):\n",
    "    \"\"\"\n",
    "    Remove unwanted elements from string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sub_df: pd DataFrame\n",
    "        dataframe containing questionnaire\n",
    "        scores in string format\n",
    "    reg_exp:    str\n",
    "        this will be the first argument in\n",
    "        re.sub()\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        sub_df w/out unwanted content\n",
    "    \"\"\"\n",
    "    sub_df = sub_df.applymap(\n",
    "                            lambda x: re.sub(reg_exp,\n",
    "                            \"\",x).rstrip()\n",
    "                            )\n",
    "    return sub_df\n",
    "\n",
    "def preprocess_subdf(in_df,substr,keys,values,rem_nl = None, strip_re = None):\n",
    "    \"\"\"\n",
    "    Preprocess questionnaire scores.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df: pd DataFrame\n",
    "        main qualtrics dataframe\n",
    "    substr: str\n",
    "        substr to identify relevant columns\n",
    "    keys:   list[str]\n",
    "        scores as they appear in OG sub_df\n",
    "    values: list[int]\n",
    "        numeric scores to replace str vals with\n",
    "    remove_newlines:\n",
    "        if provided, remove any unwanted newline\n",
    "        characters\n",
    "    strip_re: str, optional\n",
    "        provide string to use in re.sub(),\n",
    "        eg for removing brackets from survey\n",
    "        scores.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        sub_df containing numeric rather than str\n",
    "        scores.\n",
    "    \"\"\"\n",
    "    sub_df = in_df.loc[:, filter_cols(in_df,substr)]\n",
    "    # remove new line characters if needed\n",
    "    if rem_nl is not None:\n",
    "        sub_df = remove_newlines(sub_df,rounds = 2)\n",
    "    if strip_re is not None:\n",
    "        sub_df = strip_unwanted(sub_df,strip_re)\n",
    "    sub_df = repl_numeric(sub_df,make_dict(keys, values))\n",
    "    return sub_df\n",
    "\n",
    "def change_header(in_df,col_names,val_range):\n",
    "    \"\"\"\n",
    "    Change head for easier multiplication.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df:  pd DataFrame\n",
    "    col_names:  list[str]\n",
    "        columns in in_df to rename\n",
    "    val_range:  array\n",
    "        range of values ot replace\n",
    "        string names with\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    subsection of input dataframe\n",
    "    with names replaced by values in\n",
    "    val_range\n",
    "    \"\"\"\n",
    "    sub_df = in_df.loc[:,col_names]\n",
    "    sub_df.columns = val_range\n",
    "    return sub_df\n",
    "\n",
    "def reverse_scoring(sub_df, score_vals,reverse_items):\n",
    "    \"\"\"\n",
    "    For reverse scored items,\n",
    "    change score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sub_df: pd DataFrame\n",
    "        dataframe containing scores\n",
    "        to be re-scored\n",
    "    score_vals:   array\n",
    "        list of scores used for regular\n",
    "        scoring\n",
    "    reverse_items:  list[int]\n",
    "        list of items in sub_df\n",
    "        to be reverse scored. Positional\n",
    "        indexing required.\n",
    "    \"\"\"\n",
    "    new_keys = score_vals\n",
    "    new_vals = score_vals[::-1]\n",
    "    new_dict = dict(zip(new_keys,new_vals))\n",
    "    sub_df.iloc[:,reverse_items] = (\n",
    "        sub_df.iloc[:,reverse_items].applymap(\n",
    "            lambda x: new_dict[x])\n",
    "            )\n",
    "    return sub_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and preprocess qualtrics file from study day session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = r\"P:\\Spironolactone\\main_qualtrics\"\n",
    "qualtrics_df = pd.read_csv(os.path.join(main_dir, \"main_dat21.csv\"), skiprows=[1,2])\n",
    "qualtrics_df = dutils.remove_incomplete_rows(qualtrics_df, \"Finished\")\n",
    "qualtrics_df = hrvutils.remove_invalid_records(qualtrics_df,\"DQ-1\",exclude_pnums = [1],max_val = 100)\n",
    "qualtrics_df = hrvutils.remove_duplicate_participants(qualtrics_df,\"DQ-1\")\n",
    "qualtrics_df = qualtrics_df.set_index(\"DQ-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key/value pairs to create dictionaries for questionnaire scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key/value pairs\n",
    "# childhood trauma questionnaire\n",
    "ctq_keys = [\"never true\",\"rarely true\", \"sometimes true\", \"often true\", \"very often true\"]\n",
    "ctq_values = np.arange(1,6)\n",
    "# STAI\n",
    "stai_keys = [\"almost never\",\"sometimes\",\"often\", \"almost always\"]\n",
    "stai_values = np.arange(1,5)\n",
    "# ERQ\n",
    "erq_keys = [\"strongly disagree\",\"disagree\",\"slightly disagree\",\"neither agree nor disagree\", \"slightly agree\", \"agree\",\"strongly agree\"]\n",
    "erq_values = np.arange(1,8)\n",
    "# PANAS\n",
    "panas_keys = [\"very slightly or not at all\", \"a little\", \"moderately\", \"quite a bit\", \"extremely\"]\n",
    "panas_values = np.arange(1,6)\n",
    "# CADSS\n",
    "cadss_keys = [\"not at all\", \"slightly\", \"moderately\", \"considerably\", \"extremely\"]\n",
    "cadss_values = np.arange(1,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up and score all questionnaires. Note that I didn't take into account reverse scored items at first - I only realized this had to be done later, so I deal with it later on when processing scores from individual dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stai_df = preprocess_subdf(qualtrics_df,\"622_\",stai_keys,stai_values)\n",
    "ctq_df = preprocess_subdf(qualtrics_df,\"Q409_\",ctq_keys,ctq_values)\n",
    "erq_df = preprocess_subdf(qualtrics_df,\"ERQ_\",erq_keys,erq_values,2)\n",
    "panas_t1_df = preprocess_subdf(qualtrics_df,\"PANAS\",panas_keys,panas_values)\n",
    "panas_t2_df = preprocess_subdf(qualtrics_df,\"Q511_\",panas_keys,panas_values)\n",
    "panas_t3_df = preprocess_subdf(qualtrics_df,\"Q528_\",panas_keys,panas_values)\n",
    "cadss_df = preprocess_subdf(\n",
    "    qualtrics_df, \"Q594_\",cadss_keys,cadss_values,strip_re = r\"\\([^)]*\\)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now score surveys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PANAS\n",
    "pos_affect_items_panas = [\n",
    "    val-1 for val in [1,3,5,9,10,12,14,16,17,19]\n",
    "    ]\n",
    "neg_affect_items_panas = [\n",
    "    val-1 for val in [2,4,6,7,8,11,13,15,18,20]\n",
    "    ]\n",
    "\n",
    "panas_pos_scores = []\n",
    "panas_neg_scores = []\n",
    "labels = []\n",
    "\n",
    "for i,panas in enumerate([panas_t1_df,panas_t2_df,panas_t3_df]):\n",
    "    neg_affect = panas.iloc[:,neg_affect_items_panas].sum(axis = 1)\n",
    "    pos_affect = panas.iloc[:,pos_affect_items_panas].sum(axis = 1)\n",
    "    label = '_'.join([\"panas\",str(i)])\n",
    "    labels.append(label)\n",
    "    panas_pos_scores.append(pos_affect)\n",
    "    panas_neg_scores.append(neg_affect)\n",
    "\n",
    "sum_dict_keys = [\n",
    "    \"panas_t1_neg\",\"panas_t1_pos\",\"panas_t2_neg\",\n",
    "    \"panas_t2_pos\",\"panas_t3_neg\",\"panas_t3_pos\"\n",
    "    ]\n",
    "sum_dict_vals = [\n",
    "    panas_neg_scores[0],panas_pos_scores[0], panas_neg_scores[1],\n",
    "    panas_pos_scores[1],panas_neg_scores[2],panas_pos_scores[2]\n",
    "    ]\n",
    "panas_dict = dict(zip(sum_dict_keys, sum_dict_vals))\n",
    "panas_summary_df = pd.DataFrame(data = panas_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAI. Some items are reverse scored. You can account for this at an earlier stage (when replacing the string values).\n",
    "# Because I'd already done the preprocessing, I'll just replace the relevant vals here instead.\n",
    "\n",
    "stai_new_keys = stai_values\n",
    "stai_reverse_scored = [\n",
    "    val-21 for val in [21,23,26,27,30,33,34,36,39]\n",
    "    ]\n",
    "\n",
    "stai_df = reverse_scoring(stai_df,stai_values,stai_reverse_scored)\n",
    "stai_scored = stai_df.sum(axis = 1).rename(\"stai_trait\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERQ\n",
    "cra_items = [0,3,5,6,8]\n",
    "sup_items = [1,2,4,7]\n",
    "erq_cra = erq_df.iloc[:,cra_items].sum(axis = 1).rename(\"erq_cra\")\n",
    "erq_sup = erq_df.iloc[:, sup_items].sum(axis = 1).rename(\"erq_sup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket items for cat scoring\n",
    "ctq_physneg = [0,1,3,5,25]\n",
    "ctq_physab = [8,10,11,14,16]\n",
    "ctq_emneg = [4,6,27]\n",
    "ctq_emab = [2,7,13,17,24]\n",
    "ctq_valit = [9,15,21]\n",
    "ctq_sexab = [19,20,22,23,26]\n",
    "\n",
    "ctq_reverse_scored = [1,4,6,12,18,25,27]\n",
    "# change scores for reverse scored items\n",
    "ctq_df = reverse_scoring(ctq_df,ctq_values,ctq_reverse_scored)\n",
    "\n",
    "cat_list = [ctq_physneg,ctq_physab,ctq_emneg, ctq_emab, ctq_sexab, ctq_valit]\n",
    "ctq_cat_scores = []\n",
    "\n",
    "for cat in cat_list:\n",
    "    cat_sum = ctq_df.iloc[:,cat].sum(axis = 1)\n",
    "    ctq_cat_scores.append(cat_sum)\n",
    "\n",
    "ctq_cat_keys = [\n",
    "    \"ctq_physneg\",\"ctq_physab\",\"ctq_emneg\",\"ctq_emab\",\"ctq_sexab\",\"ctq_valit\"\n",
    "    ]\n",
    "ctq_cat_dict = dict(zip(ctq_cat_keys,ctq_cat_scores))\n",
    "ctq_cat_df = pd.DataFrame(data=ctq_cat_dict, index = ctq_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acute diary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "acute_diary_df = qualtrics_df.filter(like = \"Q195\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = []\n",
    "search_strings = [\n",
    "    \"\".join([\"#\",str(num),\"_\"]) for num in np.arange(1,5)\n",
    "    ]\n",
    "\n",
    "for s in search_strings:\n",
    "    cols = filter_cols(acute_diary_df,s)\n",
    "    use_cols.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace string vals with an integer\n",
    "# this is just an indicator as to whether or not they reported an intrusion.\n",
    "acute_diary_df = acute_diary_df.replace(\"0\",np.nan).replace(0,np.nan)\n",
    "acute_diary_df.loc[\n",
    "    :,use_cols[0]] = acute_diary_df.loc[:,use_cols[0]\n",
    "    ].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulate column names for easier multiplication.\n",
    "int_content_df = change_header(acute_diary_df,use_cols[0],np.arange(1,13))\n",
    "int_viv_df = change_header(acute_diary_df,use_cols[2],np.arange(1,13))\n",
    "int_dist_df = change_header(acute_diary_df,use_cols[3],np.arange(1,13))\n",
    "int_frequency_df = change_header(acute_diary_df,use_cols[1],np.arange(1,13))\n",
    "\n",
    "# calculate total number of intrusions in lab session\n",
    "int_count = int_content_df*int_frequency_df\n",
    "# calculate vividness/distress load\n",
    "viv_load = (int_frequency_df*int_viv_df).sum(axis = 1).rename(\"vividness_load\")\n",
    "dist_load = (int_frequency_df*int_dist_df).sum(axis = 1).rename(\"distress_load\")\n",
    "\n",
    "# rename memory content columns\n",
    "int_count.columns = [\"_\".join([\"memory\",str(col)]) for col in int_count.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename distress/vividness columns.\n",
    "old_names = use_cols[2:]\n",
    "new_names = [\"vividness\", \"distress\"]\n",
    "\n",
    "for i,name in enumerate(old_names):\n",
    "    new_name = [\"_\".join([new_names[i],str(val)]) for val in np.arange(1,13)]\n",
    "    mydict = dict(zip(name,new_name))\n",
    "    acute_diary_df = acute_diary_df.rename(mydict,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "acute_diary_scores_df = pd.concat(\n",
    "    [int_count,acute_diary_df.iloc[:,24:]],axis = 1\n",
    "    )\n",
    "acute_diary_scores_df[\"sum_ints\"] = (\n",
    "    acute_diary_scores_df.filter(like = \"memory\",axis = 1).sum(axis = 1)\n",
    "    )\n",
    "acute_diary_scores_df[\"vividness_load\"] = viv_load\n",
    "acute_diary_scores_df[\"distress_load\"] = dist_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate summary scores from all questionnaires and save to file.\n",
    "all_scores_df = pd.concat(\n",
    "    [panas_summary_df,stai_scored,erq_cra,erq_sup,ctq_cat_df, acute_diary_scores_df],\n",
    "    axis = 1)\n",
    "# save\n",
    "all_scores_df.to_csv(\n",
    "    os.path.join(r\"P:\\Spironolactone\",\"study_day_scores.csv\"),index = True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48186e61764c8c514947f0ef500accf59797b98e64cdc910e21ec2975c1f1025"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
