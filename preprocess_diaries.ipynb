{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script can be used to preprocess diary files (see below) and/or to remove invalid records (ie reporting no intrusions, but entering values for vividness and distress)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input directory. You may have to change this, depending on where you are running this from. os.getcwd() just gets teh current directory. Note also that the ouput directory will be created in the current directory, so either navigate to where you want things to be stored or provide an explicit directory name below (eg input_dir = r\"path\\to\\mydir\") - r is for raw string so you won't have a problem with backslashes.\n",
    "Also note: I downloaded raw qualtrics files and saved them as 'diary1.csv', 'diary2.csv',... If this is NOT what you saved the files as, you need to modify this in the list comprehension below.\n",
    "Eg if you saved the files as some_data1.csv, some_data2.csv, you need to modify the list coprehension to:\n",
    "[file for file in os.listdir(input_dir) if 'some_data' in file]\n",
    "The point is: you are identifying something that is distinct about the diary files, so you are only operating on the files you are actually interested in processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.getcwd()\n",
    "input_files = [file for file in os.listdir(input_dir) if 'diary' in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output directory, but check first if it already exists and do nothing if that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output dir\n",
    "output_dir = os.path.join(os.getcwd(),\"processed_diaries\")\n",
    "try:\n",
    "    os.makedirs(output_dir)\n",
    "except OSError:\n",
    "    # if directory already exists\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities.\n",
    "These are the functions that are used in the main body of the script below. Hopefully the names and docstrings are sufficient explanation, but happy to answer any qs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_incomplete_rows(in_df,finished_col):\n",
    "    \"\"\"\n",
    "    remove rows containing incomplete records\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df:  pd DataFrame\n",
    "        input dataframe to operate on\n",
    "    finished_col:   str\n",
    "        name of column containing complete/incomplete info\n",
    "        NB: looking for the col with BOOLEAN not %\n",
    "    Returns\n",
    "    -------\n",
    "        df w/o incomplete records\n",
    "    \"\"\"\n",
    "    in_df = in_df[in_df[finished_col]==True]\n",
    "    return in_df\n",
    "\n",
    "def rename_diary_cols(in_df, start_phrase = None, col_num = None):\n",
    "    \"\"\"\n",
    "    Rename the columns referring to diary content\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df:  pd DataFrame\n",
    "        input dataframe to operate on\n",
    "    start_phrase:   str\n",
    "        phrase to look for in column name\n",
    "    col_num:    str\n",
    "        column marker, eg \"column 1\"\n",
    "    \"\"\"\n",
    "    if col_num is None:\n",
    "        in_df = in_df.rename(columns = {in_df.filter(like = start_phrase, axis = 1).columns[0]: \"had_intrusions\"})\n",
    "    else:\n",
    "        if \"1\" in col_num:\n",
    "            new_names = ['_'.join(['content',str(num)]) for num in np.arange(1,13)]\n",
    "        elif \"2\" in col_num:\n",
    "            new_names = ['_'.join(['freq',str(num)]) for num in np.arange(1,13)]\n",
    "        elif \"3\" in col_num:\n",
    "            new_names = ['_'.join(['distress',str(num)]) for num in np.arange(1,13)]\n",
    "        else:\n",
    "            new_names = ['_'.join(['vivid',str(num)]) for num in np.arange(1,13)]\n",
    "        \n",
    "        old_names = in_df.filter(like = col_num.upper(), axis = 1).columns\n",
    "        in_df.rename(columns = dict(zip(old_names,new_names)),inplace = True)\n",
    "    return in_df\n",
    "\n",
    "def select_columns(in_df, select_list):\n",
    "    \"\"\"\n",
    "    Select columns to process.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df:  pd DataFrame\n",
    "        dataframe to operate on\n",
    "    select_list: list[str]\n",
    "        names of columns to retain\n",
    "    Returns\n",
    "    -------\n",
    "    in_df w/o irrelevant columns\n",
    "    \"\"\"\n",
    "    diary_cols = [f for f in in_df.columns\n",
    "                    if any\n",
    "                    (k in f for k in \n",
    "                    [\"had_intrusions\",\"content\",\"freq\",\"distress\",\"vivid\"])]\n",
    "    select_list.extend(diary_cols)\n",
    "    in_df = in_df.loc[:,select_list]\n",
    "    return in_df\n",
    "\n",
    "def strip_col_names(in_df):\n",
    "    \"\"\"\n",
    "    strip col names for easier handling\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    in_df:  pd dataframe\n",
    "        dataframe to operate on\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        in_df w stripped col names\n",
    "    \"\"\"\n",
    "    in_df.columns = [f.strip(\":\") for f in in_df.columns]\n",
    "    in_df.columns = [f.replace(\" \",\"_\") for f in in_df.columns]\n",
    "    return in_df\n",
    "\n",
    "def preprocess_frame(in_df,finished_col,select_list):\n",
    "    \"\"\" preprocess dataframe\"\"\"\n",
    "    in_df = remove_incomplete_rows(in_df,finished_col)\n",
    "    in_df = rename_diary_cols(in_df, start_phrase = \"have you experienced\")\n",
    "    col_nums = [' '.join(['column',str(num)]) for num in np.arange(1,5)]\n",
    "    for col in col_nums:\n",
    "        in_df = rename_diary_cols(in_df,col_num = col)\n",
    "    in_df = select_columns(in_df,select_list)\n",
    "    in_df = strip_col_names(in_df)\n",
    "    return in_df\n",
    "\n",
    "def rem_dat_no_ints(in_df):\n",
    "    \"\"\"\n",
    "    Remove data for records w/out intrusions\n",
    "    if had_intrusions == \"No\",\n",
    "    set content/vivid/freq/distress to NaN\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    in_df:  pd DataFrame\n",
    "        input dataframe to operate on\n",
    "    Returns\n",
    "    -------\n",
    "        in_df w data modified\n",
    "    \"\"\"\n",
    "    diary_cols = [col for col in in_df.columns if \n",
    "                    any(name in col for name in\n",
    "                    ['distress','vivid'])]\n",
    "    in_df.loc[in_df.had_intrusions=='No',diary_cols] = np.nan\n",
    "    return in_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main body.\n",
    "Set save = 1 if you want the processed file to be stored in output_dir, 0 if not.\n",
    "This applies the following steps:\n",
    "For each file in the input folder that contains the word 'diary':\n",
    "- remove incomplete records (retain only rows where Finished == True)\n",
    "- make the col names for the diary related stuff less unwieldy\n",
    "- remove cols we're not interested in (you can customize by passing different parameters to preprocess_dataframe (ie change the col names in [])\n",
    "- strip punctuation (:) from cols, replace whitespace with _\n",
    "- replace data in distress/vividness cols with np.nan if had_intrusions==No\n",
    "- if save, save to output_dir under name_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to output dir?\n",
    "save = 1\n",
    "for file in input_files:\n",
    "    diary_file = pd.read_csv(os.path.join(input_dir,file),skiprows = [0,2])\n",
    "    diary_file = preprocess_frame(diary_file, 'Finished',[\"Start Date\",\"Participant number:\"])\n",
    "    diary_file = rem_dat_no_ints(diary_file)\n",
    "    if save:\n",
    "        diary_file.to_csv(os.path.join(output_dir, '_'.join([file[:-4],'processed.csv'])),index = False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48186e61764c8c514947f0ef500accf59797b98e64cdc910e21ec2975c1f1025"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
