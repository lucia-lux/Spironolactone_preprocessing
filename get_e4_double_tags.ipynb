{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r\"P:\\Spironolactone\\E4\"\n",
    "main_qualtrics_dir = r\"P:\\Spironolactone\\main_qualtrics\"\n",
    "participant_folders = os.listdir(input_dir)\n",
    "participant_folders = [f for f in participant_folders if re.search(\"^p[0][0-9][0-9]\",f.lower())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_participant_num(folder_name):\n",
    "    \"\"\"\n",
    "    Get participant number from folder\n",
    "    name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_name:    str\n",
    "        Name of participant e4 data folder\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Participant number as an integer value.\n",
    "\n",
    "    \"\"\"\n",
    "    pnum = re.findall(\"p[0][0-9][0-9]\",folder_name.lower())\n",
    "    return int(pnum.pop()[1:])\n",
    "\n",
    "def flag_duplicates(folder_name):\n",
    "    \"\"\"\n",
    "    Flag duplicate E4 folders.\n",
    "    Happens when E4 recording was\n",
    "    interrupted for some reason.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_name:    str\n",
    "    Name of participant e4 data folder\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of duplicate participant numbers.\n",
    "    \"\"\"\n",
    "    parts = [num[:4] for num in participant_folders]\n",
    "    dups = [int(num[1:]) for num, count in Counter(parts).items() if count>1]\n",
    "    return dups\n",
    "\n",
    "def remove_multindex(in_df, axis, level):\n",
    "    \"\"\"\n",
    "    Remove multi index of specified level\n",
    "    along specified axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_df:  pd DataFrame\n",
    "        df to operate on\n",
    "    axis:   int\n",
    "        rows = 0\n",
    "        cols = 1\n",
    "    level:  int\n",
    "        level of multindex to remove.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe with specified level of multiindex\n",
    "    removed\n",
    "    \"\"\"\n",
    "    if axis == 0:\n",
    "        out_df = in_df.reset_index(level = level, drop = True)\n",
    "    else:\n",
    "        out_df = in_df.T.reset_index(level = level, drop = True).T\n",
    "    return out_df\n",
    "    \n",
    "def get_rowdiff(values):\n",
    "    \"\"\"\n",
    "    calculate difference\n",
    "    between rows of series\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    values\n",
    "\n",
    "    Returns\n",
    "        differences between successive\n",
    "        rows\n",
    "    \"\"\"\n",
    "    if len(values)<=1:\n",
    "        return values\n",
    "    else:\n",
    "        new_vals = []\n",
    "        for i,val in enumerate(values):\n",
    "            if i==0:\n",
    "                new_val = val\n",
    "            else:\n",
    "                new_val = val-values[i-1]\n",
    "            new_vals.append(new_val)\n",
    "    return new_vals\n",
    "\n",
    "def find_min_delta(tag_deltas, axis = 0):\n",
    "    \"\"\"\n",
    "    find minimum difference\n",
    "    between successive tags.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tag_deltas: pd DataFrame\n",
    "        dataframe of row-to-row differences\n",
    "    axis:   int\n",
    "        0 for min row  w/in col\n",
    "        1 for min col w/in row\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        min value for each column (participant)\n",
    "    \"\"\"\n",
    "    min_diffs = tag_deltas.apply(lambda x: min(x),axis = axis)\n",
    "    return min_diffs\n",
    "\n",
    "def return_likely_doubles(min_deltas, time_delta_df, threshold):\n",
    "    \"\"\"\n",
    "    find likely double tags\n",
    "    based on min delta\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    min_deltas: pd Series\n",
    "        minimum difference between rows\n",
    "        for each participant\n",
    "    time_delta_df:  pd DataFrame\n",
    "        dataframe representing differences\n",
    "        between successive rows\n",
    "    threshold:  float\n",
    "        min_deltas will be multiplied by\n",
    "        threshold to define an acceptable\n",
    "        window for identifying double tags\n",
    "        eg: look for row differences less than\n",
    "        1.5*min_deltas, where 1.5 would represent\n",
    "        thresh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        time_delta_df masked with nan where\n",
    "        threshold exceeded. Non-nan values\n",
    "        represent possible double tags.\n",
    "    \"\"\"\n",
    "    double_tag_df = time_delta_df[\n",
    "                                time_delta_df<=min_deltas*threshold\n",
    "                                ].dropna(how = \"all\",axis = 0)\n",
    "    return double_tag_df\n",
    "\n",
    "def get_num_double_tags(double_tag_df):\n",
    "    \"\"\"\n",
    "    Get number of double tags\n",
    "    detected in dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    double_tag_df:  pd DataFrame\n",
    "        dataframe with value for likely\n",
    "        double tags, NaN elswhere\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    value counts of double tags identfied\n",
    "    \"\"\"\n",
    "    double_counts = double_tag_df.apply(\n",
    "                                        lambda x:\n",
    "                                        x.notna().sum()\n",
    "                                        ).value_counts()\n",
    "    return double_counts\n",
    "\n",
    "def get_best_thresh(tag_val_counts):\n",
    "    \"\"\"\n",
    "    get threshold that maximises\n",
    "    number of double tags detected\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tag_val_counts: list of tuples\n",
    "        of type [(two_counts, threshold)]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        Threshold at which max number of \n",
    "        two double tags were detected.\n",
    "\n",
    "    \"\"\"\n",
    "    max_num = max([val[0] for val in tag_val_counts])\n",
    "    max_threshold = [thresh for (num,thresh)\n",
    "                    in tag_val_counts if num == max_num]\n",
    "    if len(max_threshold)>1:\n",
    "        print(f\"More than 1 max val detected. Manual check advised.\")\n",
    "    return max_threshold\n",
    "\n",
    "def detect_missing_doubles(double_tags_df):\n",
    "    \"\"\"\n",
    "    Flag participants with (possible)\n",
    "    missing double_tags.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    num_tags = double_tags_df.apply(\n",
    "                                    lambda x: len(x.dropna())\n",
    "                                    )\n",
    "    flags_df = num_tags[num_tags != 2]\n",
    "    flags_df = flags_df.reset_index()\n",
    "    flags_df.columns = [\"pnum\",\"num_double_tags\"]\n",
    "    return flags_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in tag files for all participants and assemble those w/o duplicates into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than one tag file exists for participant 1. Skipping.\n",
      "More than one tag file exists for participant 1. Skipping.\n",
      "More than one tag file exists for participant 10. Skipping.\n",
      "More than one tag file exists for participant 10. Skipping.\n",
      "More than one tag file exists for participant 20. Skipping.\n",
      "More than one tag file exists for participant 20. Skipping.\n",
      "More than one tag file exists for participant 27. Skipping.\n",
      "More than one tag file exists for participant 27. Skipping.\n"
     ]
    }
   ],
   "source": [
    "missing_tags = []\n",
    "pnums = []\n",
    "tags_dat = []\n",
    "duplicates = flag_duplicates(participant_folders)\n",
    "\n",
    "for folder in participant_folders:\n",
    "    pnum = get_participant_num(folder)\n",
    "    if pnum in duplicates:\n",
    "        print(f\"More than one tag file exists for participant {pnum}. Skipping.\")\n",
    "        continue\n",
    "    try:\n",
    "        tags_df = pd.read_csv(os.path.join(input_dir,folder,\"tags.csv\"),header = 0,names = [pnum])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No tags file found for participant {pnum}.Manual check advised.\")\n",
    "        missing_tags.append(pnum)\n",
    "        continue\n",
    "    pnums.append(pnum)\n",
    "    tags_dat.append(tags_df)\n",
    "\n",
    "tags_df = pd.concat(tags_dat,axis = 1,keys =[pnum for pnum in pnums])\n",
    "tags_df = remove_multindex(tags_df,1,1)\n",
    "#tags_df = tags_df.apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for likely double tags based on time between successive tags. There is no \"hard and fast\" criterion, but given the fact that (a) they're only supposed to double-tag twice and (b) double tags are supposed to happen in quick succession (with no other button press supposed to be quicker), the approach used here is based on the following steps:\n",
    "(i) Look for the smallest row difference for each participant (where participants = columns, rows = tags).\n",
    "(ii) Look for row differences within a certain above this minimum difference (threshold is chosen based on the value that maximises the number of double tags detected).\n",
    "(iii) Count the number of double tags detected.\n",
    "(iv) Flag those participants for whom (for a given threshold) either too few or too many double tags were detected.\n",
    "These participants can then be checked manually, or we can check whether the words 'tag' or 'E4' are mentioned in their session notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_diff_df = tags_df.apply(lambda x: get_rowdiff(x))\n",
    "min_deltas = find_min_delta(tags_diff_df)\n",
    "thresholds = np.arange(1.5,5,0.5)\n",
    "all_tag_vals = []\n",
    "for thresh in thresholds:\n",
    "    double_df = return_likely_doubles(min_deltas, tags_diff_df, thresh)\n",
    "    tag_vals = get_num_double_tags(double_df)\n",
    "    num_twos = tag_vals[2]\n",
    "    all_tag_vals.append((num_twos,thresh))\n",
    "max_thresh = get_best_thresh(all_tag_vals)\n",
    "double_df = return_likely_doubles(min_deltas, tags_diff_df,max_thresh)\n",
    "detect_missing_doubles_df = detect_missing_doubles(double_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualtrics_df = pd.read_csv(os.path.join(main_qualtrics_dir,\"main_dat.csv\"),skiprows = [1,2],usecols = [\"DQ-1\", \"NOTES\"])\n",
    "qualtrics_df.columns = [\"pnum\",\"session_notes\"]\n",
    "qualtrics_df = qualtrics_df.drop(labels = qualtrics_df[qualtrics_df.session_notes.isna()].index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10     3.0\n",
       "11     4.0\n",
       "16    10.0\n",
       "18    12.0\n",
       "19    17.0\n",
       "21    18.0\n",
       "22     9.0\n",
       "32    16.0\n",
       "34    27.0\n",
       "35    19.0\n",
       "37    29.0\n",
       "Name: pnum, dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substr = [\"tag\",\"e4\"]\n",
    "reg_substr = \"|\".join(substr)\n",
    "qualtrics_df.loc[qualtrics_df[\"session_notes\"].str.lower().str.contains(reg_substr),'pnum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pnum</th>\n",
       "      <th>num_double_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pnum  num_double_tags\n",
       "0      6                1\n",
       "1     11                1\n",
       "2     12                1\n",
       "3     13                1\n",
       "4     14                0\n",
       "5     16                1\n",
       "6     24                1\n",
       "7     29                1\n",
       "8     30                1\n",
       "9     32                1\n",
       "10    34                1\n",
       "11    35                4"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_missing_doubles_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48186e61764c8c514947f0ef500accf59797b98e64cdc910e21ec2975c1f1025"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
